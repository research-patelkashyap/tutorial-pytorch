{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "* Tensors are specialized data structures that are similar to arrays and matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly from Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Numpy Array\n",
    "\n",
    "* When a tensor is created directly from a NumPy array, both share the same underlying memory location. This means that modifying the contents of one (either the NumPy array or the tensor) will reflect in the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy np_array value: \n",
      " [[1 2]\n",
      " [3 4]] \n",
      "\n",
      "Tensor x_np value: \n",
      " tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "Numpy np_array after * 2 operation: \n",
      " [[2 4]\n",
      " [6 8]] \n",
      "\n",
      "Tensor x_np value after modifying numpy array: \n",
      " tensor([[2, 4],\n",
      "        [6, 8]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "print(f\"Numpy np_array value: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value: \\n {x_np} \\n\")\n",
    "\n",
    "np.multiply(np_array, 2, out=np_array)\n",
    "\n",
    "print(f\"Numpy np_array after * 2 operation: \\n {np_array} \\n\")\n",
    "print(f\"Tensor x_np value after modifying numpy array: \\n {x_np} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Another Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.3825, 0.3551],\n",
      "        [0.4537, 0.9124]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Random or Constant Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.3714, 0.6878, 0.4040],\n",
      "        [0.8650, 0.6712, 0.6861]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPS Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "  tensor = tensor.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row:  tensor([1., 1., 1., 1.])\n",
      "First column:  tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print('First row: ',tensor[0])\n",
    "print('First column: ', tensor[:, 0])\n",
    "print('Last column:', tensor[..., -1])\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arithmetic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y2: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y3: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "z1: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z2: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z3: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = tensor @ tensor.T\n",
    "print(f\"y1: {y1}\")\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "print(f\"y2: {y2}\")\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "print(f\"y3: {y3}\")\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor\n",
    "print(f\"z1: {z1}\")\n",
    "z2 = tensor.mul(tensor)\n",
    "print(f\"z2: {z2}\")\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(f\"z3: {z3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Element Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()  \n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Place Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor to Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "\n",
    "Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.\n",
    "\n",
    "* root is the path where the train/test data is stored.\n",
    "* train specifies training or test dataset.\n",
    "* download=True downloads the data from the Internet if it's not available at root.\n",
    "* transform and target_transform specify the feature and label transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [02:17<00:00, 191806.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 186135.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:24<00:00, 182339.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 871218.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Training Data\n",
    "\n",
    "* data: The training data we'll use to train the model, and the test data to evaluate the model.\n",
    "* batch size: The number of records to be processed in each batch.\n",
    "* shuffle: The random sample of the data by indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAeGUlEQVR4nO3db2yV9f3/8VeB9rRIe7CU/pM/FvzDItJlKF2jMpQG6DYjyg113oDFaHDFTJm4sKioM+nGEmdcGO6GgZmJMpMB0SUsWm3JtoIBJYw5G0rqqKEtgvYc2kJb2s/vBj/Pd0co5fpwznm3h+cj+ST0nOvd693rXD0vrp7TdzOcc04AAKTYGOsGAACXJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJsZZN/BNg4ODOnr0qHJzc5WRkWHdDgAgIOecTp48qdLSUo0ZM/R1zogLoKNHj2rq1KnWbQAALlFra6umTJky5P0j7kdwubm51i0AABJguOfzpAXQhg0bdPXVVys7O1sVFRX68MMPL6qOH7sBQHoY7vk8KQG0detWrV69WuvWrdNHH32k8vJyLV68WMeOHUvG7gAAo5FLgnnz5rmamprYxwMDA660tNTV1tYOWxuJRJwkFovFYo3yFYlELvh8n/AroL6+Pu3bt09VVVWx28aMGaOqqio1Njaes31vb6+i0WjcAgCkv4QH0PHjxzUwMKCioqK424uKitTe3n7O9rW1tQqHw7HFO+AA4PJg/i64tWvXKhKJxFZra6t1SwCAFEj47wEVFBRo7Nix6ujoiLu9o6NDxcXF52wfCoUUCoUS3QYAYIRL+BVQVlaW5s6dq7q6uthtg4ODqqurU2VlZaJ3BwAYpZIyCWH16tVavny5brrpJs2bN08vvfSSuru79eMf/zgZuwMAjEJJCaB7771XX3zxhZ555hm1t7fr29/+tnbu3HnOGxMAAJevDOecs27if0WjUYXDYes2AACXKBKJKC8vb8j7zd8FBwC4PBFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwMc66gdHohz/8YeCar776KnBNU1NT4Jovv/wycM3g4GDgGgC4VFwBAQBMEEAAABMJD6Bnn31WGRkZcWvWrFmJ3g0AYJRLymtAN9xwg957773/28k4XmoCAMRLSjKMGzdOxcXFyfjUAIA0kZTXgA4dOqTS0lLNmDFDDzzwgI4cOTLktr29vYpGo3ELAJD+Eh5AFRUV2rx5s3bu3KmNGzeqpaVFt912m06ePHne7WtraxUOh2Nr6tSpiW4JADACZTjnXDJ30NnZqenTp+vFF1/Ugw8+eM79vb296u3tjX0cjUZHfAjxe0AAMLxIJKK8vLwh70/6uwMmTpyo6667Ts3Nzee9PxQKKRQKJbsNAMAIk/TfA+rq6tLhw4dVUlKS7F0BAEaRhAfQE088oYaGBn322Wf65z//qbvvvltjx47V/fffn+hdAQBGsYT/CO7zzz/X/fffrxMnTmjy5Mm69dZbtXv3bk2ePDnRuwIAjGJJfxNCUNFoVOFwOCX7+te//uVVN2nSpMA1bW1tgWt83hxw0003Ba45ePBg4BpJqqurC1zj83qfzy8yjxnjd3HvU+fzqwM9PT2Ba8aOHRu4JpXf3j79ZWRkpGQ/Z86cCVwjyeulg6uuuipwjc/XdKEX9y+kvLzcq87HcG9CYBYcAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE0n/g3Qjmc9fD5Wk3NzcwDU+Qxd9aj799NPANVlZWYFrJOmOO+5Iyb58anyHkfoMgPXZl29/QfmcQ1LqBov6SNUAU0nq7+8PXNPX1xe45vTp04FrfIaeSn4Dgf/3r1YnEldAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATaTMNe9euXYFrSkpKvPblM7k2Ozs7Jfs5fvx44BrfScE+E50zMzMD1/hMFx4YGAhcI/lNw/Y9fkGdOXMmcI3vhGqfxylVfM67ceNS91TnnAtcc8UVVwSu+eqrrwLXSNKKFSsC17z66quBtnfOXdT3IFdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATKTNMNJJkyYFrsnKyvLal89wzJ6ensA1PkMufYae+vQm+R0/n4GaPgNC+/v7A9dIfsM7fQZd+gxL9RlO6zuMdPz48YFrfI6DzznuM4zUp0byGyzq8zj5DH/16U2SnnrqqcA1QZ8j+vr6tHXr1mG34woIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAibQZRvrCCy8ErlmzZo3XvnwGn/oMG/QZ1JiTkxO4xncoq89ATZ/Boj5DLn2HT/rweZxS9TX5Hgefc8LnsfXhc975Dqf1kapBs6FQKHCNJDU1NQWuCXq+Xuy5wBUQAMAEAQQAMBE4gHbt2qU777xTpaWlysjI0Pbt2+Pud87pmWeeUUlJiXJyclRVVaVDhw4lql8AQJoIHEDd3d0qLy/Xhg0bznv/+vXr9fLLL+uVV17Rnj17dMUVV2jx4sVeP+MEAKSvwK+EVldXq7q6+rz3Oef00ksv6amnntJdd90lSXrttddUVFSk7du367777ru0bgEAaSOhrwG1tLSovb1dVVVVsdvC4bAqKirU2Nh43pre3l5Fo9G4BQBIfwkNoPb2dklSUVFR3O1FRUWx+76ptrZW4XA4tqZOnZrIlgAAI5T5u+DWrl2rSCQSW62trdYtAQBSIKEBVFxcLEnq6OiIu72joyN23zeFQiHl5eXFLQBA+ktoAJWVlam4uFh1dXWx26LRqPbs2aPKyspE7goAMMoFfhdcV1eXmpubYx+3tLRo//79ys/P17Rp0/TYY4/phRde0LXXXquysjI9/fTTKi0t1dKlSxPZNwBglAscQHv37tXtt98e+3j16tWSpOXLl2vz5s168skn1d3drYcfflidnZ269dZbtXPnTmVnZyeuawDAqBc4gBYsWCDn3JD3Z2Rk6Pnnn9fzzz9/SY0FNWXKlMA1vqHY29sbuObMmTOBa3wGSfoMXczIyAhc41vncxx8+/Phc/x8HiefAaapPA4+g0V9Bu5e6LlkKD7nkM+A0FTuy2c4re+vrPz73/8OXBN0gOnFHjfzd8EBAC5PBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATwUewppGsrCyvOp9JwamakNvX1xe4xnfKss9EZ58an4nJvnyOuc807FQZ6RO0fR5bnxrf7/Xx48cHrvH5HvSZzO+zH0m64YYbAtd0dnYG2v5in+9G7ncOACCtEUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJE2w0h9BhT6Dmr02ZfPwEqf/nyGffpK5ZDQdOMzuNPnfPAdlOrz2PoMx/QZ/pqqIbiSlJmZGbjGZ/DpmTNnAtfk5+cHrpGk6667LnDNiRMnAm1/sec3V0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMpM0wUh++Awp9Bgf6Dj4dqfvx3ZfvcMx04zOMNJUDd334fD/5nA8DAwOBa3wGpUrSqVOnAtf4DCPNzc0NXOP72C5YsCBwTUdHh9e+hsOzAQDABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNpM4zUZ1Cj72DMVA14TNXAylTyOXbp+DWlagin77Hz+ZrGjQv+dOIzwNSnt/7+/sA1vnwGi/oMOP7iiy8C10hSQ0ODV10ycAUEADBBAAEATAQOoF27dunOO+9UaWmpMjIytH379rj7V6xYoYyMjLi1ZMmSRPULAEgTgQOou7tb5eXl2rBhw5DbLFmyRG1tbbH1xhtvXFKTAID0E/hVw+rqalVXV19wm1AopOLiYu+mAADpLymvAdXX16uwsFDXX3+9HnnkEZ04cWLIbXt7exWNRuMWACD9JTyAlixZotdee011dXX69a9/rYaGBlVXVw/5FtLa2lqFw+HYmjp1aqJbAgCMQAn/PaD77rsv9u8bb7xRc+bM0cyZM1VfX6+FCxees/3atWu1evXq2MfRaJQQAoDLQNLfhj1jxgwVFBSoubn5vPeHQiHl5eXFLQBA+kt6AH3++ec6ceKESkpKkr0rAMAoEvhHcF1dXXFXMy0tLdq/f7/y8/OVn5+v5557TsuWLVNxcbEOHz6sJ598Utdcc40WL16c0MYBAKNb4ADau3evbr/99tjHX79+s3z5cm3cuFEHDhzQH//4R3V2dqq0tFSLFi3SL3/5S4VCocR1DQAY9QIH0IIFCy444PBvf/vbJTXkKzs7O3CNzyBEyW8oZFZWVuCaVA0j9dmPL5+Blaka/urLp79U1aSSz4BVn68pVQNMJenKK68MXNPX1xe4pqurK3CNz9BTSSooKAhcc/z4ca99DYdZcAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwn/k9xWUvnnHs6cORO4xnfydlA+E4l9JlRLfpO3UzXR2Xc/qfqaUjXp3Pc4pOpx8pks78P3Ly339/cHrvniiy8C1/j0N378+MA1kt/XlCxcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADCRNsNIfQZqpmrgouQ3dDFVX5PvcfAZfJoqPsM+pZE9YDWVUjVg1Uc4HA5c09fX57Wvrq6uwDU+51BmZmZK9iP5Dx9OhpH7DAIASGsEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMjJypdJcoFAqlbF8+QwB9BgBmZWUFrvEZCJnKoaI+Qy59hy768Bka6/M1+Rxzn+Pg+9j61I0dOzZwjc8Qzv7+/sA1X375ZeAaScrJyQlcM2HChMA1PsNSfY63lNrnyuFwBQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBE2gwj7e7uDlzjO8zPZ/jkmTNnAtekamigzwBTX77HPKienh6vOp/+fAbN+gzU9KlJ5TDSyZMnB67p6uoKXPPZZ58FrgmHw4FrJL/H1megbW9vb+Aan6Gnkt+Q42ThCggAYIIAAgCYCBRAtbW1uvnmm5Wbm6vCwkItXbpUTU1NcducPn1aNTU1mjRpkiZMmKBly5apo6MjoU0DAEa/QAHU0NCgmpoa7d69W++++676+/u1aNGiuNdfHn/8cb399tt666231NDQoKNHj+qee+5JeOMAgNEt0CtsO3fujPt48+bNKiws1L59+zR//nxFIhG9+uqr2rJli+644w5J0qZNm/Stb31Lu3fv1ne/+93EdQ4AGNUu6TWgSCQiScrPz5ck7du3T/39/aqqqoptM2vWLE2bNk2NjY3n/Ry9vb2KRqNxCwCQ/rwDaHBwUI899phuueUWzZ49W5LU3t6urKwsTZw4MW7boqIitbe3n/fz1NbWKhwOx9bUqVN9WwIAjCLeAVRTU6ODBw/qzTffvKQG1q5dq0gkElutra2X9PkAAKOD1y+irlq1Su+884527dqlKVOmxG4vLi5WX1+fOjs7466COjo6VFxcfN7PFQqFUvYLlwCAkSPQFZBzTqtWrdK2bdv0/vvvq6ysLO7+uXPnKjMzU3V1dbHbmpqadOTIEVVWViamYwBAWgh0BVRTU6MtW7Zox44dys3Njb2uEw6HlZOTo3A4rAcffFCrV69Wfn6+8vLy9Oijj6qyspJ3wAEA4gQKoI0bN0qSFixYEHf7pk2btGLFCknSb3/7W40ZM0bLli1Tb2+vFi9erN///vcJaRYAkD4CBZBzbthtsrOztWHDBm3YsMG7KR+nTp0KXJOZmem1r6KiosA1PoMafYZP+riYx/V8+vr6Atf4DEIcScMTMbSvfy0jiEmTJgWumT59euCaVPryyy8D1/gMOM7Ozg5cI0njx4/3qksGZsEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEx4/UXUkchncvRrr72WhE7Ob8KECYFrfCbk+kyOHjfO7zTw+Uu2PhPIt27dGrhm7969gWuks3/bKqgrr7wycE1OTk7gGh++E9V9+luzZk3gmr/+9a+Baw4ePBi4JpUT1X0m8/tMEvedYv/JJ5941SUDV0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMZDjfiXZJEo1GvQZCAgBGlkgkory8vCHv5woIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIlAAVRbW6ubb75Zubm5Kiws1NKlS9XU1BS3zYIFC5SRkRG3Vq5cmdCmAQCjX6AAamhoUE1NjXbv3q13331X/f39WrRokbq7u+O2e+ihh9TW1hZb69evT2jTAIDRb1yQjXfu3Bn38ebNm1VYWKh9+/Zp/vz5sdvHjx+v4uLixHQIAEhLl/QaUCQSkSTl5+fH3f7666+roKBAs2fP1tq1a9XT0zPk5+jt7VU0Go1bAIDLgPM0MDDgfvCDH7hbbrkl7vY//OEPbufOne7AgQPuT3/6k7vqqqvc3XffPeTnWbdunZPEYrFYrDRbkUjkgjniHUArV65006dPd62trRfcrq6uzklyzc3N573/9OnTLhKJxFZra6v5QWOxWCzWpa/hAijQa0BfW7Vqld555x3t2rVLU6ZMueC2FRUVkqTm5mbNnDnznPtDoZBCoZBPGwCAUSxQADnn9Oijj2rbtm2qr69XWVnZsDX79++XJJWUlHg1CABIT4ECqKamRlu2bNGOHTuUm5ur9vZ2SVI4HFZOTo4OHz6sLVu26Pvf/74mTZqkAwcO6PHHH9f8+fM1Z86cpHwBAIBRKsjrPhri53ybNm1yzjl35MgRN3/+fJefn+9CoZC75ppr3Jo1a4b9OeD/ikQi5j+3ZLFYLNalr+Ge+zP+f7CMGNFoVOFw2LoNAMAlikQiysvLG/J+ZsEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEyMuAByzlm3AABIgOGez0dcAJ08edK6BQBAAgz3fJ7hRtglx+DgoI4eParc3FxlZGTE3ReNRjV16lS1trYqLy/PqEN7HIezOA5ncRzO4jicNRKOg3NOJ0+eVGlpqcaMGfo6Z1wKe7ooY8aM0ZQpUy64TV5e3mV9gn2N43AWx+EsjsNZHIezrI9DOBwedpsR9yM4AMDlgQACAJgYVQEUCoW0bt06hUIh61ZMcRzO4jicxXE4i+Nw1mg6DiPuTQgAgMvDqLoCAgCkDwIIAGCCAAIAmCCAAAAmRk0AbdiwQVdffbWys7NVUVGhDz/80LqllHv22WeVkZERt2bNmmXdVtLt2rVLd955p0pLS5WRkaHt27fH3e+c0zPPPKOSkhLl5OSoqqpKhw4dsmk2iYY7DitWrDjn/FiyZIlNs0lSW1urm2++Wbm5uSosLNTSpUvV1NQUt83p06dVU1OjSZMmacKECVq2bJk6OjqMOk6OizkOCxYsOOd8WLlypVHH5zcqAmjr1q1avXq11q1bp48++kjl5eVavHixjh07Zt1ayt1www1qa2uLrb///e/WLSVdd3e3ysvLtWHDhvPev379er388st65ZVXtGfPHl1xxRVavHixTp8+neJOk2u44yBJS5YsiTs/3njjjRR2mHwNDQ2qqanR7t279e6776q/v1+LFi1Sd3d3bJvHH39cb7/9tt566y01NDTo6NGjuueeewy7TryLOQ6S9NBDD8WdD+vXrzfqeAhuFJg3b56rqamJfTwwMOBKS0tdbW2tYVept27dOldeXm7dhilJbtu2bbGPBwcHXXFxsfvNb34Tu62zs9OFQiH3xhtvGHSYGt88Ds45t3z5cnfXXXeZ9GPl2LFjTpJraGhwzp197DMzM91bb70V2+Y///mPk+QaGxut2ky6bx4H55z73ve+537605/aNXURRvwVUF9fn/bt26eqqqrYbWPGjFFVVZUaGxsNO7Nx6NAhlZaWasaMGXrggQd05MgR65ZMtbS0qL29Pe78CIfDqqiouCzPj/r6ehUWFur666/XI488ohMnTli3lFSRSESSlJ+fL0nat2+f+vv7486HWbNmadq0aWl9PnzzOHzt9ddfV0FBgWbPnq21a9eqp6fHor0hjbhhpN90/PhxDQwMqKioKO72oqIiffrpp0Zd2aioqNDmzZt1/fXXq62tTc8995xuu+02HTx4ULm5udbtmWhvb5ek854fX993uViyZInuuecelZWV6fDhw/rFL36h6upqNTY2auzYsdbtJdzg4KAee+wx3XLLLZo9e7aks+dDVlaWJk6cGLdtOp8P5zsOkvSjH/1I06dPV2lpqQ4cOKCf//znampq0l/+8hfDbuON+ADC/6muro79e86cOaqoqND06dP15z//WQ8++KBhZxgJ7rvvvti/b7zxRs2ZM0czZ85UfX29Fi5caNhZctTU1OjgwYOXxeugFzLUcXj44Ydj/77xxhtVUlKihQsX6vDhw5o5c2aq2zyvEf8juIKCAo0dO/acd7F0dHSouLjYqKuRYeLEibruuuvU3Nxs3YqZr88Bzo9zzZgxQwUFBWl5fqxatUrvvPOOPvjgg7g/31JcXKy+vj51dnbGbZ+u58NQx+F8KioqJGlEnQ8jPoCysrI0d+5c1dXVxW4bHBxUXV2dKisrDTuz19XVpcOHD6ukpMS6FTNlZWUqLi6OOz+i0aj27Nlz2Z8fn3/+uU6cOJFW54dzTqtWrdK2bdv0/vvvq6ysLO7+uXPnKjMzM+58aGpq0pEjR9LqfBjuOJzP/v37JWlknQ/W74K4GG+++aYLhUJu8+bN7pNPPnEPP/ywmzhxomtvb7duLaV+9rOfufr6etfS0uL+8Y9/uKqqKldQUOCOHTtm3VpSnTx50n388cfu448/dpLciy++6D7++GP33//+1znn3K9+9Ss3ceJEt2PHDnfgwAF31113ubKyMnfq1CnjzhPrQsfh5MmT7oknnnCNjY2upaXFvffee+473/mOu/baa93p06etW0+YRx55xIXDYVdfX+/a2tpiq6enJ7bNypUr3bRp09z777/v9u7d6yorK11lZaVh14k33HFobm52zz//vNu7d69raWlxO3bscDNmzHDz58837jzeqAgg55z73e9+56ZNm+aysrLcvHnz3O7du61bSrl7773XlZSUuKysLHfVVVe5e++91zU3N1u3lXQffPCBk3TOWr58uXPu7Fuxn376aVdUVORCoZBbuHCha2pqsm06CS50HHp6etyiRYvc5MmTXWZmpps+fbp76KGH0u4/aef7+iW5TZs2xbY5deqU+8lPfuKuvPJKN378eHf33Xe7trY2u6aTYLjjcOTIETd//nyXn5/vQqGQu+aaa9yaNWtcJBKxbfwb+HMMAAATI/41IABAeiKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDi/wFEMMUC9+IbnwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Bag\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "label_name = list(labels_map.values())[label]\n",
    "print(f\"Label: {label_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation\n",
    "\n",
    "Transforms are used to manipulate data and prepare it for training. In PyTorch's TorchVision library, all datasets include two key parameters: transform (for modifying features) and target_transform (for modifying labels). These parameters accept callables that define the transformation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()\n",
       "Target transform: Lambda()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The input layer with 28x28 or 784 features/pixels.\n",
    "* The first linear module takes the input 784 features and transforms it to a hidden layer with 512 features.\n",
    "* The ReLU activation function will be applied in the transformation.\n",
    "* The second linear module takes 512 features as input from the first hidden layer and transforms it to the next hidden layer with 512 features.\n",
    "* The ReLU activation function will be applied in the transformation.\n",
    "* The third linear module take 512 features as input from the second hidden layer and transforms those features to the output layer with 10, which is the number of classes.\n",
    "* The ReLU activation function will be applied in the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X) \n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Linear weights: Parameter containing:\n",
      "tensor([[ 0.0102,  0.0016,  0.0197,  ...,  0.0343, -0.0204, -0.0353],\n",
      "        [ 0.0109, -0.0159,  0.0169,  ...,  0.0183,  0.0277, -0.0128],\n",
      "        [ 0.0143, -0.0213, -0.0200,  ...,  0.0030,  0.0356, -0.0185],\n",
      "        ...,\n",
      "        [-0.0007,  0.0354, -0.0300,  ...,  0.0323,  0.0327,  0.0321],\n",
      "        [ 0.0195, -0.0153,  0.0173,  ...,  0.0259,  0.0009, -0.0342],\n",
      "        [ 0.0327, -0.0345, -0.0004,  ...,  0.0043, -0.0147,  0.0090]],\n",
      "       device='mps:0', requires_grad=True) \n",
      "\n",
      "First Linear biases: Parameter containing:\n",
      "tensor([-5.3004e-03, -1.7104e-02, -2.1123e-02, -2.0188e-02, -1.1326e-02,\n",
      "         1.0873e-02,  3.5702e-02,  3.3968e-02, -2.7796e-02, -7.4486e-03,\n",
      "        -2.0755e-02,  2.3051e-02,  4.8806e-03,  1.8657e-02, -3.1216e-02,\n",
      "        -1.5101e-02, -2.3973e-02, -2.5694e-02,  1.5950e-02, -5.9867e-03,\n",
      "        -6.0845e-03, -2.6912e-02, -1.8191e-02,  2.1619e-02, -1.1859e-02,\n",
      "        -1.1167e-02,  3.2029e-02,  1.6026e-02,  2.2725e-02, -2.2231e-02,\n",
      "        -8.4556e-03,  3.3132e-02,  1.3302e-02, -1.7152e-02, -2.9110e-02,\n",
      "        -1.0211e-02, -5.6610e-03, -2.3762e-02, -3.4852e-02, -3.0468e-02,\n",
      "         1.4136e-02, -1.8024e-02,  3.4019e-02, -2.5654e-02, -2.0505e-02,\n",
      "         2.5115e-02,  1.3204e-02, -1.1135e-02,  3.0747e-02,  2.9112e-03,\n",
      "        -1.7009e-02,  5.2681e-03,  1.5624e-02,  7.4339e-03,  2.5945e-02,\n",
      "        -2.8240e-02, -7.5022e-03,  7.2257e-04,  2.9738e-02, -3.3043e-02,\n",
      "         6.2401e-03,  1.5302e-03,  4.8957e-03, -3.3089e-02,  2.3530e-02,\n",
      "        -4.6705e-03,  1.7145e-02, -2.3571e-02,  2.3174e-02, -1.1736e-02,\n",
      "         3.3989e-02,  3.4383e-02,  2.8323e-02, -3.3332e-02,  2.3142e-02,\n",
      "        -1.6913e-02,  1.3919e-02,  3.3310e-03, -1.3350e-02, -1.9359e-02,\n",
      "         4.1869e-03,  1.6602e-02, -3.3109e-02, -1.7625e-02,  2.9350e-02,\n",
      "         2.2430e-03,  3.3378e-02, -3.0552e-02,  1.3272e-02,  8.2884e-03,\n",
      "        -3.5615e-02, -3.4367e-02,  8.8438e-03, -3.1693e-02,  3.3984e-02,\n",
      "         3.2236e-02, -5.1152e-03, -2.2250e-03, -2.6171e-02, -2.9237e-03,\n",
      "         1.9352e-02,  2.2287e-02, -2.1803e-02, -3.0721e-02, -8.6138e-03,\n",
      "        -7.5763e-04,  2.9232e-02,  7.1388e-03, -2.2271e-02, -6.4771e-03,\n",
      "        -3.0784e-02, -8.9549e-04,  3.3994e-02, -1.1782e-02, -3.1121e-02,\n",
      "         3.4920e-03,  3.1020e-02, -2.4107e-02,  1.3167e-02, -3.2459e-02,\n",
      "        -2.4423e-02,  3.5681e-02, -1.0023e-02,  1.3364e-02,  2.0386e-02,\n",
      "         2.1433e-02,  1.2516e-02, -3.2165e-02,  9.3652e-05, -3.3790e-02,\n",
      "         1.8750e-02,  2.4570e-02, -3.0533e-02, -3.4004e-02,  2.4168e-02,\n",
      "        -1.7924e-02, -1.3305e-02, -2.7913e-02,  6.3104e-03, -2.7361e-02,\n",
      "        -2.0128e-02, -3.2051e-02,  1.6542e-02,  4.4104e-03, -5.7657e-03,\n",
      "        -8.4299e-03, -1.4954e-02, -6.4515e-03, -4.3568e-03,  1.7662e-02,\n",
      "         3.1418e-02, -3.2060e-02,  1.7615e-02, -2.6677e-02,  2.9356e-02,\n",
      "         9.3090e-03,  1.8292e-02, -4.9615e-04, -2.6052e-02, -1.2350e-02,\n",
      "         1.1005e-03,  3.4079e-04,  6.8844e-03,  1.9262e-02,  1.3887e-02,\n",
      "         4.3393e-03, -3.1682e-02,  6.5901e-05, -3.4524e-03,  3.4085e-03,\n",
      "        -3.3560e-02,  1.3962e-02,  5.0311e-03, -7.2275e-03,  3.0021e-03,\n",
      "        -1.5278e-02,  3.1334e-02, -6.9705e-03,  4.2959e-03, -3.2097e-02,\n",
      "         2.6020e-02,  2.8579e-02, -3.7043e-03, -3.2882e-02,  2.0960e-02,\n",
      "         1.4627e-02,  1.9880e-02, -2.5043e-02,  2.2673e-02, -3.4913e-02,\n",
      "        -1.8228e-02,  1.0970e-02,  2.1416e-02,  3.2544e-02,  4.6540e-03,\n",
      "         9.8858e-03,  2.9641e-02,  2.4408e-02,  2.9331e-03,  2.1324e-02,\n",
      "        -7.4726e-04, -1.8814e-02,  9.8685e-03, -1.2324e-02,  2.1865e-02,\n",
      "         1.7584e-02, -2.7692e-02,  2.0143e-03, -1.6587e-03, -3.8960e-03,\n",
      "        -1.7193e-02,  2.2397e-02, -3.4790e-02, -2.5650e-02, -8.2347e-03,\n",
      "        -1.2275e-02,  2.7542e-02,  9.5101e-03, -2.4569e-02,  2.7201e-02,\n",
      "         2.8516e-02,  2.0888e-03,  3.0707e-02,  2.6437e-02, -1.2080e-02,\n",
      "         2.0896e-02,  1.1580e-04,  1.6788e-02,  2.0297e-02,  1.7723e-03,\n",
      "        -1.7528e-03,  2.6266e-02, -1.4501e-02, -3.4407e-02,  2.6020e-02,\n",
      "         1.5256e-02,  1.5284e-02, -3.8871e-03,  2.2556e-03, -3.2479e-02,\n",
      "        -9.0145e-03, -2.1292e-02, -3.0998e-02,  1.1024e-02,  1.8234e-02,\n",
      "        -1.9900e-02,  1.2834e-02, -3.0858e-02, -1.3645e-03,  2.8259e-02,\n",
      "         2.4415e-03, -1.5903e-02,  3.2963e-02, -2.5938e-02, -2.9792e-02,\n",
      "        -1.4520e-02,  1.4144e-02, -2.0743e-02, -8.4065e-03, -1.8755e-02,\n",
      "         3.1144e-02,  2.1336e-02,  2.8461e-02, -6.7945e-03, -1.3278e-02,\n",
      "         1.7867e-02,  2.8144e-02, -2.3423e-02,  3.6934e-03, -2.5958e-02,\n",
      "        -3.0495e-02, -1.0238e-02, -3.3290e-02,  3.8995e-03, -3.2401e-03,\n",
      "        -2.3931e-02, -1.0124e-02, -1.6296e-02, -2.7680e-02, -1.1558e-02,\n",
      "         1.3695e-03,  2.0842e-02,  2.9339e-02,  2.6938e-02, -2.0710e-02,\n",
      "        -3.2124e-02, -2.0388e-02,  2.4436e-02,  1.5300e-02, -2.4966e-02,\n",
      "        -3.4980e-02,  7.6069e-03,  2.7749e-02,  1.4136e-03, -3.3788e-02,\n",
      "         7.4569e-04, -3.3588e-02, -3.5366e-02, -1.7129e-02,  1.3299e-02,\n",
      "         3.4971e-02,  1.2779e-02, -1.1448e-02, -4.0989e-03, -1.0271e-02,\n",
      "        -1.3561e-02,  1.1802e-02,  9.6346e-03, -3.1891e-02, -3.3320e-03,\n",
      "         2.5375e-02, -4.2881e-04,  3.0872e-02, -3.2627e-02, -2.5209e-02,\n",
      "        -2.3998e-02,  8.0280e-03,  3.4646e-02,  3.5389e-02,  4.6391e-03,\n",
      "         3.0949e-02,  1.2904e-02,  1.3166e-02,  7.7800e-03, -1.8964e-02,\n",
      "         2.8736e-02,  3.3581e-02,  3.2567e-03, -2.7819e-02,  3.0544e-02,\n",
      "         3.0165e-02, -1.7046e-02,  2.9647e-02, -1.5801e-03,  2.3439e-02,\n",
      "         4.1065e-03,  1.3030e-02,  1.5639e-02, -4.9340e-03,  3.0641e-02,\n",
      "        -1.5032e-02,  1.0041e-02, -2.7904e-02,  3.5272e-02,  3.4859e-02,\n",
      "         1.3155e-02, -1.3264e-02,  5.8468e-03, -2.9689e-02, -1.7519e-02,\n",
      "         9.5681e-03, -1.1110e-02, -2.3186e-02, -7.0580e-03,  2.7495e-02,\n",
      "        -2.5067e-02,  3.0493e-02, -3.2023e-02,  3.2521e-02, -2.6858e-03,\n",
      "        -2.7679e-02,  7.4359e-03,  2.3794e-02,  1.8609e-02, -5.8339e-03,\n",
      "         2.1849e-02,  2.7095e-02, -7.8261e-03, -3.3730e-03,  2.6779e-03,\n",
      "         2.8949e-02, -3.1711e-02,  1.0106e-02, -6.2932e-03, -3.1051e-02,\n",
      "        -1.1550e-02,  8.8197e-03, -4.4973e-03, -3.3256e-02,  2.7702e-02,\n",
      "         1.9349e-02,  1.7686e-02,  7.8901e-03,  4.2748e-03, -6.3803e-03,\n",
      "        -1.9885e-02,  2.7538e-02,  3.1624e-02, -1.0998e-02, -1.2523e-02,\n",
      "        -1.8759e-02,  2.7130e-02, -4.5948e-03,  1.0671e-02, -1.7509e-02,\n",
      "         3.0995e-02,  1.8850e-02,  1.4516e-02, -4.7155e-04, -2.1630e-02,\n",
      "         2.7209e-03,  2.7418e-02, -3.1050e-02, -1.1176e-02,  2.2077e-02,\n",
      "         2.8880e-02,  1.4268e-02, -1.4542e-02, -2.9195e-02,  1.2018e-02,\n",
      "        -3.0897e-02,  2.0109e-02,  7.9046e-03, -2.4680e-02,  2.2453e-02,\n",
      "         2.2264e-02,  4.5142e-03,  3.9588e-03,  3.4290e-03,  3.5347e-02,\n",
      "        -1.4554e-02,  1.8398e-02,  1.4268e-02,  2.8656e-02, -8.3784e-04,\n",
      "         3.1443e-03, -1.0851e-02,  3.5007e-02,  1.4896e-02, -2.1071e-02,\n",
      "        -1.8488e-02,  8.4933e-03,  1.1898e-02, -2.2702e-02, -8.7354e-03,\n",
      "        -1.1667e-02,  1.5990e-04,  1.3443e-02, -1.5975e-02,  1.0042e-02,\n",
      "        -2.3406e-02,  2.5013e-05, -7.3096e-03,  2.4140e-02, -2.7465e-02,\n",
      "         1.6628e-02,  2.4527e-02,  1.9631e-02,  2.6730e-02,  1.3918e-02,\n",
      "        -3.1316e-02, -2.7564e-02,  2.1561e-02, -2.3265e-02, -3.0458e-03,\n",
      "         5.2987e-03, -5.1563e-03,  1.7458e-02, -1.0460e-03,  1.3482e-02,\n",
      "         2.6943e-02,  1.2094e-02, -3.1720e-02,  2.4345e-02,  4.5847e-03,\n",
      "        -6.8249e-03, -6.2091e-03,  3.2796e-02, -5.2384e-03,  3.0934e-02,\n",
      "        -1.3194e-05,  3.2533e-03, -8.0474e-03,  3.5259e-03, -1.5024e-02,\n",
      "         1.0089e-02, -9.8877e-03,  7.0653e-03, -8.6487e-03, -5.8642e-03,\n",
      "         7.4874e-03,  2.5678e-02,  1.2838e-02, -1.0446e-02, -3.0218e-02,\n",
      "         1.8944e-02, -1.5005e-02,  3.0596e-02, -1.8954e-02,  3.0068e-02,\n",
      "        -1.8712e-02, -3.0575e-02,  3.2803e-02, -1.1125e-03, -1.4902e-02,\n",
      "        -1.1140e-02,  1.0213e-02, -1.6465e-02, -2.2147e-02, -9.3018e-03,\n",
      "        -9.4231e-03, -3.2691e-02, -2.6510e-02, -1.4226e-03, -1.8861e-02,\n",
      "        -2.0499e-02, -5.5331e-03,  3.6597e-03,  1.0815e-02, -9.2105e-03,\n",
      "         1.1640e-03, -1.5984e-02], device='mps:0', requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "print(f\"First Linear biases: {model.linear_relu_stack[0].bias} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.2002, -0.2451, -0.2622, -0.2436, -0.1526, -0.0698,  0.7661, -0.2043,\n",
      "         -0.5890,  0.0989,  0.1012,  0.2216, -0.0093, -0.7611, -0.0758,  0.5887,\n",
      "         -0.3490, -0.1654,  0.2605,  0.2229],\n",
      "        [ 0.3001, -0.0756,  0.1667, -0.5455, -0.0644,  0.0722,  0.8106, -0.5248,\n",
      "         -0.4934,  0.2588, -0.4740,  0.3194,  0.1706, -0.2033, -0.3236,  0.5526,\n",
      "         -0.0461, -0.3348,  0.3117,  0.3727],\n",
      "        [ 0.2459, -0.0321,  0.0894, -0.5004, -0.3707, -0.6600,  0.4325, -0.5829,\n",
      "         -0.0645,  0.2094,  0.0660,  0.4071,  0.2414, -0.5106, -0.1434,  0.3172,\n",
      "         -0.2105, -0.3958,  0.1265,  0.2590]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.2002, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7661, 0.0000, 0.0000,\n",
      "         0.0989, 0.1012, 0.2216, 0.0000, 0.0000, 0.0000, 0.5887, 0.0000, 0.0000,\n",
      "         0.2605, 0.2229],\n",
      "        [0.3001, 0.0000, 0.1667, 0.0000, 0.0000, 0.0722, 0.8106, 0.0000, 0.0000,\n",
      "         0.2588, 0.0000, 0.3194, 0.1706, 0.0000, 0.0000, 0.5526, 0.0000, 0.0000,\n",
      "         0.3117, 0.3727],\n",
      "        [0.2459, 0.0000, 0.0894, 0.0000, 0.0000, 0.0000, 0.4325, 0.0000, 0.0000,\n",
      "         0.2094, 0.0660, 0.4071, 0.2414, 0.0000, 0.0000, 0.3172, 0.0000, 0.0000,\n",
      "         0.1265, 0.2590]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2296, -0.2267, -0.0740,  0.0535, -0.2042,  0.3551, -0.0840,  0.0565,\n",
       "          0.1872, -0.2204],\n",
       "        [ 0.3107, -0.0522, -0.0347,  0.0273, -0.3234,  0.3541,  0.0387,  0.0520,\n",
       "          0.2230, -0.2811],\n",
       "        [ 0.3183, -0.0492, -0.1185,  0.0208, -0.2328,  0.2276,  0.0333, -0.0567,\n",
       "          0.3086, -0.2992]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1225, 0.0777, 0.0905, 0.1028, 0.0794, 0.1389, 0.0896, 0.1031, 0.1175,\n",
       "         0.0781],\n",
       "        [0.1293, 0.0899, 0.0915, 0.0974, 0.0686, 0.1350, 0.0985, 0.0998, 0.1184,\n",
       "         0.0715],\n",
       "        [0.1326, 0.0918, 0.0857, 0.0985, 0.0764, 0.1211, 0.0997, 0.0912, 0.1314,\n",
       "         0.0715]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0102,  0.0016,  0.0197,  ...,  0.0343, -0.0204, -0.0353],\n",
      "        [ 0.0109, -0.0159,  0.0169,  ...,  0.0183,  0.0277, -0.0128]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0053, -0.0171], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0014, -0.0176,  0.0154,  ..., -0.0127,  0.0351,  0.0098],\n",
      "        [-0.0371,  0.0442, -0.0312,  ...,  0.0310,  0.0433, -0.0099]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0241, -0.0409], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0423,  0.0297,  0.0219,  ..., -0.0212,  0.0306, -0.0061],\n",
      "        [ 0.0363, -0.0339, -0.0373,  ..., -0.0291, -0.0257,  0.0003]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0175, 0.0088], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x177da8880>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x177da8880>\n"
     ]
    }
   ],
   "source": [
    "print('Gradient function for z =',z.grad_fn)\n",
    "print('Gradient function for loss =', loss.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0657, 0.0011, 0.1606],\n",
      "        [0.0657, 0.0011, 0.1606],\n",
      "        [0.0657, 0.0011, 0.1606],\n",
      "        [0.0657, 0.0011, 0.1606],\n",
      "        [0.0657, 0.0011, 0.1606]])\n",
      "tensor([0.0657, 0.0011, 0.1606])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling Gradient Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "z.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Another way\n",
    "\n",
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Gradients and Jacobian Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)\n",
    "\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)\n",
    "\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of Epochs: The number times the entire training dataset is passed through the network.\n",
    "* Batch Size: The number of data samples the model sees in each epoch. This iterates over the number of batches needed to complete an epoch.\n",
    "* Learning Rate: The size of steps that the model matches as it searches for the best weights that will produce a higher model accuracy. Smaller values mean the model takes longer to find the best weights. Larger values might result in the model stepping over and missing the best weights, which yields unpredictable behavior during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Train Loop: Iterates over the training dataset and tries to converge to optimal parameters.\n",
    "* The Validation/Test Loop: Iterates over the test dataset to check if model performance is improving.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Common loss functions include:\n",
    "\n",
    "* nn.MSELoss: Mean Square Error, used for regression tasks.\n",
    "* nn.NLLLoss: Negative Log Likelihood, used for classification.\n",
    "* nn.CrossEntropyLoss: Combines nn.LogSoftmax and nn.NLLLoss.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Inside the training loop, optimization happens in three steps:\n",
    "\n",
    "1. Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "2. Back-propagate the prediction loss with a call to loss.backwards(). PyTorch deposits the gradients of the loss with respect to each parameter.\n",
    "3. Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306779  [    0/60000]\n",
      "loss: 2.303441  [ 6400/60000]\n",
      "loss: 2.288326  [12800/60000]\n",
      "loss: 2.284169  [19200/60000]\n",
      "loss: 2.285147  [25600/60000]\n",
      "loss: 2.260109  [32000/60000]\n",
      "loss: 2.264499  [38400/60000]\n",
      "loss: 2.246955  [44800/60000]\n",
      "loss: 2.232064  [51200/60000]\n",
      "loss: 2.211804  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.7%, Avg loss: 0.034943 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.222986  [    0/60000]\n",
      "loss: 2.240163  [ 6400/60000]\n",
      "loss: 2.205508  [12800/60000]\n",
      "loss: 2.212583  [19200/60000]\n",
      "loss: 2.210191  [25600/60000]\n",
      "loss: 2.155017  [32000/60000]\n",
      "loss: 2.168262  [38400/60000]\n",
      "loss: 2.134649  [44800/60000]\n",
      "loss: 2.101915  [51200/60000]\n",
      "loss: 2.075234  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.2%, Avg loss: 0.033076 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.096137  [    0/60000]\n",
      "loss: 2.140226  [ 6400/60000]\n",
      "loss: 2.073942  [12800/60000]\n",
      "loss: 2.093557  [19200/60000]\n",
      "loss: 2.093020  [25600/60000]\n",
      "loss: 1.997472  [32000/60000]\n",
      "loss: 2.009965  [38400/60000]\n",
      "loss: 1.952029  [44800/60000]\n",
      "loss: 1.896849  [51200/60000]\n",
      "loss: 1.867907  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.7%, Avg loss: 0.030249 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.903461  [    0/60000]\n",
      "loss: 1.987843  [ 6400/60000]\n",
      "loss: 1.870737  [12800/60000]\n",
      "loss: 1.915080  [19200/60000]\n",
      "loss: 1.913002  [25600/60000]\n",
      "loss: 1.758468  [32000/60000]\n",
      "loss: 1.778241  [38400/60000]\n",
      "loss: 1.674324  [44800/60000]\n",
      "loss: 1.658228  [51200/60000]\n",
      "loss: 1.587969  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.0%, Avg loss: 0.026504 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.651594  [    0/60000]\n",
      "loss: 1.766689  [ 6400/60000]\n",
      "loss: 1.605379  [12800/60000]\n",
      "loss: 1.731022  [19200/60000]\n",
      "loss: 1.681705  [25600/60000]\n",
      "loss: 1.491170  [32000/60000]\n",
      "loss: 1.563788  [38400/60000]\n",
      "loss: 1.418192  [44800/60000]\n",
      "loss: 1.484504  [51200/60000]\n",
      "loss: 1.377818  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.023727 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.460232  [    0/60000]\n",
      "loss: 1.602176  [ 6400/60000]\n",
      "loss: 1.417628  [12800/60000]\n",
      "loss: 1.609661  [19200/60000]\n",
      "loss: 1.536137  [25600/60000]\n",
      "loss: 1.323972  [32000/60000]\n",
      "loss: 1.430800  [38400/60000]\n",
      "loss: 1.265006  [44800/60000]\n",
      "loss: 1.380828  [51200/60000]\n",
      "loss: 1.256797  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.022018 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.344316  [    0/60000]\n",
      "loss: 1.501500  [ 6400/60000]\n",
      "loss: 1.297541  [12800/60000]\n",
      "loss: 1.523914  [19200/60000]\n",
      "loss: 1.446119  [25600/60000]\n",
      "loss: 1.223954  [32000/60000]\n",
      "loss: 1.344152  [38400/60000]\n",
      "loss: 1.170522  [44800/60000]\n",
      "loss: 1.312254  [51200/60000]\n",
      "loss: 1.177728  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 0.020817 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.266106  [    0/60000]\n",
      "loss: 1.430676  [ 6400/60000]\n",
      "loss: 1.207894  [12800/60000]\n",
      "loss: 1.454545  [19200/60000]\n",
      "loss: 1.380642  [25600/60000]\n",
      "loss: 1.153925  [32000/60000]\n",
      "loss: 1.281921  [38400/60000]\n",
      "loss: 1.105012  [44800/60000]\n",
      "loss: 1.262912  [51200/60000]\n",
      "loss: 1.121136  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.5%, Avg loss: 0.019911 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.208627  [    0/60000]\n",
      "loss: 1.377473  [ 6400/60000]\n",
      "loss: 1.139239  [12800/60000]\n",
      "loss: 1.397551  [19200/60000]\n",
      "loss: 1.331842  [25600/60000]\n",
      "loss: 1.101670  [32000/60000]\n",
      "loss: 1.235752  [38400/60000]\n",
      "loss: 1.057469  [44800/60000]\n",
      "loss: 1.227401  [51200/60000]\n",
      "loss: 1.079651  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.7%, Avg loss: 0.019229 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.164746  [    0/60000]\n",
      "loss: 1.336857  [ 6400/60000]\n",
      "loss: 1.086913  [12800/60000]\n",
      "loss: 1.352326  [19200/60000]\n",
      "loss: 1.296963  [25600/60000]\n",
      "loss: 1.062278  [32000/60000]\n",
      "loss: 1.201726  [38400/60000]\n",
      "loss: 1.022501  [44800/60000]\n",
      "loss: 1.200653  [51200/60000]\n",
      "loss: 1.047869  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.0%, Avg loss: 0.018718 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model/model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Running Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import torch.onnx as onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7p/_l5kmmts4m3886n2ycnm87380000gn/T/ipykernel_8799/2223051616.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model/model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load('model/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.zeros((1,28,28))\n",
    "onnx_model = 'model/model.onnx'\n",
    "onnx.export(model, input_image, onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "x, y = test_data[0][0], test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "session = onnxruntime.InferenceSession(onnx_model, None)\n",
    "input_name = session.get_inputs()[0].name\n",
    "output_name = session.get_outputs()[0].name\n",
    "\n",
    "result = session.run([output_name], {input_name: x.numpy()})\n",
    "predicted, actual = classes[result[0][0].argmax(0)], classes[y]\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnnbctfd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
